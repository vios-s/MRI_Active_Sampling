{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-30T17:48:32.662207Z",
     "end_time": "2023-11-30T17:48:32.721752Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Z:\\\\data\\\\fastMRI\\\\knee\\\\retain_singlecoil_test'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 12\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m((label \u001B[38;5;28;01mfor\u001B[39;00m fname, slice_val, label, fname_list \u001B[38;5;129;01min\u001B[39;00m label_list \u001B[38;5;28;01mif\u001B[39;00m fname \u001B[38;5;241m==\u001B[39m target_fname \u001B[38;5;129;01mand\u001B[39;00m fname_list[target_slice] \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mstr\u001B[39m(target_slice)), \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     11\u001B[0m root \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mZ:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdata/fastMRI\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mknee/retain_singlecoil_test/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 12\u001B[0m files \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m fname \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(files):\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(fname)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1160\u001B[0m, in \u001B[0;36mPath.iterdir\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1156\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21miterdir\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1157\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001B[39;00m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;124;03m    result for the special paths '.' and '..'.\u001B[39;00m\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_accessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1161\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m'\u001B[39m}:\n\u001B[0;32m   1162\u001B[0m             \u001B[38;5;66;03m# Yielding a path object for these makes little sense\u001B[39;00m\n\u001B[0;32m   1163\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'Z:\\\\data\\\\fastMRI\\\\knee\\\\retain_singlecoil_test'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "def read_sample_label(list_path):\n",
    "        with open(list_path) as metalist:\n",
    "            datalist = csv.reader(metalist, delimiter=',')\n",
    "            return [(row[0], int(row[1]), row[2]) for row in datalist if datalist.line_num > 1]\n",
    "def find_label(label_list, target_fname, target_slice):\n",
    "        return next((label for fname, slice_val, label, fname_list in label_list if fname == target_fname and fname_list[target_slice] == str(target_slice)), None)\n",
    "\n",
    "\n",
    "root = 'Z:\\data/fastMRI\\knee/retain_singlecoil_test/'\n",
    "files = list(Path(root).iterdir())\n",
    "for fname in sorted(files):\n",
    "    print(fname)\n",
    "    print(fname.name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "import csv\n",
    "import h5py\n",
    "import yaml\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as etree\n",
    "from pathlib import Path\n",
    "from warnings import warn\n",
    "from typing import NamedTuple, Dict, Any, Union, Optional, Callable, Tuple, Sequence\n",
    "import pandas as pd\n",
    "\n",
    "root = '../Dataset/label.csv'\n",
    "data_root = 'Z:/data/fastMRI\\knee\\singlecoil_train'\n",
    "def read_sample_label(list_path):\n",
    "    # Assuming the CSV file has columns: 'file', 'slice', 'label'\n",
    "    label_df = pd.read_csv(list_path, header=0, names=['file', 'slice', 'label'])\n",
    "    return label_df\n",
    "\n",
    "def find_label(label_list, target_fname, target_slice):\n",
    "    # Assuming label_list is a DataFrame with columns: 'file', 'slice', 'label'\n",
    "    filtered_rows = label_list.loc[(label_list['file'] == target_fname) & (label_list['slice'] == target_slice)]\n",
    "    if not filtered_rows.empty:\n",
    "        return filtered_rows['label'].values[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def remove_h5_extension(fname):\n",
    "    return os.path.splitext(fname.name)[0]\n",
    "\n",
    "def et_query(\n",
    "    root: etree.Element,\n",
    "    qlist: Sequence[str],\n",
    "    namespace: str = \"http://www.ismrm.org/ISMRMRD\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ElementTree query function.\n",
    "\n",
    "    This can be used to query an xml document via ElementTree. It uses qlist\n",
    "    for nested queries.\n",
    "\n",
    "    Args:\n",
    "        root: Root of the xml to search through.\n",
    "        qlist: A list of strings for nested searches, e.g. [\"Encoding\",\n",
    "            \"matrixSize\"]\n",
    "        namespace: Optional; xml namespace to prepend query.\n",
    "\n",
    "    Returns:\n",
    "        The retrieved data as a string.\n",
    "    \"\"\"\n",
    "    s = \".\"\n",
    "    prefix = \"ismrmrd_namespace\"\n",
    "\n",
    "    ns = {prefix: namespace}\n",
    "\n",
    "    for el in qlist:\n",
    "        s = s + f\"//{prefix}:{el}\"\n",
    "\n",
    "    value = root.find(s, ns)\n",
    "    if value is None:\n",
    "        raise RuntimeError(\"Element not found\")\n",
    "\n",
    "    return str(value.text)\n",
    "\n",
    "\n",
    "def fetch_dir(key: str, data_config_file=\"fastmri_dirs.yaml\") -> Path:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        key (_type_): key to retrieve path from data_config_file. Expected to be in\n",
    "            (\"knee_path\", \"brain_path\", \"log_path\").\n",
    "        data_config_file (str, optional): Default path config file to fetch path\n",
    "            from. Defaults to \"fastmri_dirs.yaml\".\n",
    "\n",
    "    Returns:\n",
    "        Path: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    data_config_file = Path(data_config_file)\n",
    "    if not data_config_file.is_file():\n",
    "        default_config = {\n",
    "            \"knee_path\": \"Dataset/fastMRI/\",\n",
    "            \"brain_path\": \"Dataset/FastMRI/\",\n",
    "            \"log_path\": \"logs/\",\n",
    "        }\n",
    "\n",
    "        with open(data_config_file, \"w\") as f:\n",
    "            yaml.dump(default_config, f)\n",
    "\n",
    "        data_dir = default_config[key]\n",
    "\n",
    "        warn(\n",
    "            f\"Path config at {data_config_file.resolve()} does not exist. \"\n",
    "            \"A template has been created for you. \"\n",
    "            \"Please enter the directory paths for your system to have defaults.\"\n",
    "        )\n",
    "    else:\n",
    "        with open(data_config_file, \"r\") as f:\n",
    "            data_dir = yaml.safe_load(f)[key]\n",
    "\n",
    "    return Path(data_dir)\n",
    "\n",
    "\n",
    "class FastMRIRawDataSample(NamedTuple):\n",
    "    \"\"\"Basic data type for fastMRI raw data.\n",
    "\n",
    "    Elements:\n",
    "        fname: Path for each h5 file, Path\n",
    "        slice_ind: slice index, int\n",
    "        metadata: metadata for each volume, Dict\n",
    "    \"\"\"\n",
    "    fname: Path\n",
    "    slice_ind: int\n",
    "    label: list\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "def _retrieve_metadata(fname):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        fname (_type_):\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    with h5py.File(fname, 'r') as hf:\n",
    "        et_root = etree.fromstring(hf['ismrmrd_header'][()])\n",
    "\n",
    "        enc = [\"encoding\", \"encodedSpace\", \"matrixSize\"]\n",
    "        enc_size = (\n",
    "            int(et_query(et_root, enc + [\"x\"])), #640\n",
    "            int(et_query(et_root, enc + [\"y\"])), # 372\n",
    "            int(et_query(et_root, enc + [\"z\"])), # 1\n",
    "        )\n",
    "        rec = [\"encoding\", \"reconSpace\", \"matrixSize\"]\n",
    "        recon_size = (\n",
    "            int(et_query(et_root, rec + [\"x\"])), # 320\n",
    "            int(et_query(et_root, rec + [\"y\"])), # 320\n",
    "            int(et_query(et_root, rec + [\"z\"])), # 1\n",
    "        )\n",
    "\n",
    "        lims = [\"encoding\", \"encodingLimits\", \"kspace_encoding_step_1\"]\n",
    "        enc_limits_center = int(et_query(et_root, lims + [\"center\"])) # 167\n",
    "        enc_limits_max = int(et_query(et_root, lims + [\"maximum\"])) + 1 # 334\n",
    "\n",
    "        padding_left = enc_size[1] // 2 - enc_limits_center # 372 // 2 - 167 = 19\n",
    "        padding_right = padding_left + enc_limits_max # 19 + 334 = 353\n",
    "\n",
    "        num_slices = hf[\"kspace\"].shape[0]\n",
    "\n",
    "        metadata = {\n",
    "            \"padding_left\": padding_left,\n",
    "            \"padding_right\": padding_right,\n",
    "            \"encoding_size\": enc_size,\n",
    "            \"recon_size\": recon_size,\n",
    "            **hf.attrs\n",
    "        }\n",
    "\n",
    "    return metadata, num_slices\n",
    "\n",
    "\n",
    "\n",
    "raw_samples = []\n",
    "# * if there is a filter\n",
    "raw_sample_filter = None\n",
    "if raw_sample_filter is None:\n",
    "    raw_sample_filter = lambda raw_sample: True\n",
    "else:\n",
    "    raw_sample_filter = raw_sample_filter\n",
    "\n",
    "label_list = read_sample_label(root)\n",
    "files = list(Path(data_root).iterdir())\n",
    "for fname in sorted(files):\n",
    "    metadata, num_slices = _retrieve_metadata(fname)\n",
    "    new_raw_samples = []\n",
    "    for slice_ind in range(num_slices):\n",
    "        label = find_label(label_list, remove_h5_extension(fname), slice_ind)\n",
    "        print(label)\n",
    "        raw_sample = FastMRIRawDataSample(fname, slice_ind, label, metadata)\n",
    "        if raw_sample_filter(raw_sample):\n",
    "            new_raw_samples.append(raw_sample)\n",
    "    raw_samples += new_raw_samples\n",
    "    # print(raw_samples)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T05:04:18.852820Z",
     "end_time": "2024-01-15T05:05:28.551891Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "size_all =[]\n",
    "for i in range(len(raw_samples)):\n",
    "    fname, dataslice, label, metadata = raw_samples[i]\n",
    "    if label == 1:\n",
    "        # print(fname, dataslice, label, metadata)\n",
    "        with h5py.File(fname, \"r\") as hf:\n",
    "            kspace = hf[\"kspace\"][dataslice]\n",
    "            size_all.append(np.shape(hf[\"kspace\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T13:31:13.488336Z",
     "end_time": "2024-01-15T13:35:48.309108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.shape(size_all))\n",
    "from matplotlib import pyplot as plt\n",
    "new = np.array(size_all)\n",
    "\n",
    "print(np.shape(new))\n",
    "\n",
    "print(max(new[:,0]),max(new[:,1]),max(new[:,2]))\n",
    "print(min(new[:,0]),min(new[:,1]),min(new[:,2]))\n",
    "# Plotting a basic histogram\n",
    "plt.hist(new[:,2], bins=100, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Basic Histogram')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T13:38:29.941167Z",
     "end_time": "2024-01-15T13:38:30.124869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = np.stack((kspace.real, kspace.imag), axis=-1)\n",
    "print(data)\n",
    "data = torch.from_numpy(data)\n",
    "print(np.shape(data))\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-14T01:24:52.246189Z",
     "end_time": "2024-01-14T01:24:52.308903Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_mask(data: torch.Tensor, mask_func: MaskFunc, offset: Optional[int]=None,\n",
    "                seed: Optional[Union[int, Tuple[int, ...]]]=None, padding: Optional[Sequence[int]]=None):\n",
    "\n",
    "    shape = (1,) * len(data.shape[:-3]) + tuple(data.shape[-3:]) # (1, 1, 640, 372, 2)\n",
    "    print(shape)\n",
    "    mask, num_low_freqs = mask_func(shape, offset, seed)\n",
    "    if padding is not None:\n",
    "        mask[..., :padding[0], :] = 0\n",
    "        mask[..., padding[1]:, :] = 0\n",
    "\n",
    "    # * add 0.0 removes the sign of the zeros\n",
    "    masked_data = data * mask + 0.0\n",
    "\n",
    "    return masked_data, mask, num_low_freqs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-14T23:55:37.824403Z",
     "end_time": "2024-01-14T23:55:37.847251Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.fft import fft2c, ifft2c\n",
    "from masking import create_mask_for_mask_type\n",
    "mask = create_mask_for_mask_type('random', [0.08], [4])\n",
    "mask_func = None\n",
    "image = ifft2c(data)\n",
    "noisy_masked_kspace, mask_, _ = apply_mask(data,mask, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-14T23:58:52.178545Z",
     "end_time": "2024-01-14T23:58:52.236780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.shape(mask_))\n",
    "print(np.shape(noisy_masked_kspace))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-14T23:58:54.570440Z",
     "end_time": "2024-01-14T23:58:54.603729Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(noisy_masked_kspace[:,:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-14T23:58:59.156972Z",
     "end_time": "2024-01-14T23:58:59.290701Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range[2:5]:\n",
    " print(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, 2, requires_grad=True)\n",
    "target = torch.rand(3, 2, requires_grad=False)\n",
    "output = loss(torch.sigmoid(input), target)\n",
    "output.backward()\n",
    "print(input, target)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(torch.sigmoid(input), target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-16T00:55:59.309646Z",
     "end_time": "2024-01-16T00:55:59.350811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "loss = nn.BCELoss()\n",
    "original_labels = torch.tensor([0, 1, 0, 1, 0, 1])\n",
    "one_hot_label = F.one_hot(original_labels , num_classes=2).float()\n",
    "input = torch.randn(6, 2, requires_grad=True)\n",
    "# loss = loss(torch.sigmoid(input), one_hot_label)\n",
    "acc = (input.argmax(dim=-1) == original_labels).float().mean()\n",
    "print(acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-16T13:49:58.718172Z",
     "end_time": "2024-01-16T13:49:58.781176Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming your original labels are stored in a list or numpy array\n",
    "original_labels = [0, 1, 0, 1, 0, 1]\n",
    "\n",
    "# Convert binary labels to one-hot encoded labels\n",
    "one_hot_labels = np.eye(2)[original_labels]\n",
    "\n",
    "print(\"Original Labels:\", original_labels)\n",
    "print(\"One-Hot Encoded Labels:\")\n",
    "for label in one_hot_labels:\n",
    "    print(label)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T04:00:33.689426Z",
     "end_time": "2024-01-15T04:00:33.734564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T04:01:58.620994Z",
     "end_time": "2024-01-15T04:01:58.652976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load pre-trained ResNet-50\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Access 'layer4'\n",
    "layer4 = resnet50.layer4\n",
    "\n",
    "# Now 'layer4' contains the fourth block of ResNet-50\n",
    "print(layer4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-16T14:53:30.523826Z",
     "end_time": "2024-01-16T14:53:33.385392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "print(input,target)\n",
    "output.backward()\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T04:05:25.730144Z",
     "end_time": "2024-01-15T04:05:25.799382Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming your one-hot encoded labels are stored in a 2D array\n",
    "one_hot_labels = np.array([[0.5, 0], [0, 1], [1, 0], [0, 1], [1, 0]])\n",
    "\n",
    "# Convert one-hot encoded labels to original labels\n",
    "original_labels = np.argmax(one_hot_labels, axis=1)\n",
    "\n",
    "print(\"One-Hot Encoded Labels:\")\n",
    "for label in one_hot_labels:\n",
    "    print(label)\n",
    "\n",
    "print(\"Original Labels:\", original_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T04:19:57.535661Z",
     "end_time": "2024-01-15T04:19:57.574151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "\n",
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(input, target)\n",
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-16T00:16:32.487894Z",
     "end_time": "2024-01-16T00:16:32.510588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "loss = F.binary_cross_entropy_with_logits(input, target)\n",
    "loss.backward()\n",
    "print(input,target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-16T00:18:34.894229Z",
     "end_time": "2024-01-16T00:18:34.944880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "len_ds = 60461\n",
    "counts = {'A': 6775, 'B': 3609, 'C': 906}\n",
    "\n",
    "\n",
    "def create_data(which_class: str):\n",
    "    arr = np.zeros((1, len_ds))\n",
    "    arr[:, :counts[which_class]] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "data = {k: create_data(k) for k in counts}\n",
    "data = np.concatenate((data['A'], data['B'], data['C']), axis=0)\n",
    "\n",
    "label_df = pd.DataFrame(data).transpose()\n",
    "label_df.columns = [*counts.keys()]\n",
    "label_df = shuffle(label_df)\n",
    "label_df.reset_index(inplace=True, drop=True)\n",
    "print(label_df[label_df == 1].count())\n",
    "\n",
    "\n",
    "class toy_dataset(Dataset):\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(label_df.iloc[index].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(label_df)\n",
    "\n",
    "\n",
    "dataset = toy_dataset()\n",
    "\n",
    "\n",
    "def calculateWeights(label_dict, d_set):\n",
    "    arr = []\n",
    "    for label, count in label_dict.items():\n",
    "        weight = len(d_set) / count\n",
    "        arr.append(weight)\n",
    "    return arr\n",
    "\n",
    "\n",
    "weights = calculateWeights(counts, dataset)\n",
    "weights = torch.DoubleTensor(weights)\n",
    "print('weights: ', weights)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(dataset), replacement=True)\n",
    "trainloader = DataLoader(dataset, batch_size=50, sampler=sampler,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0, pin_memory=False)\n",
    "\n",
    "all_labels = torch.Tensor()\n",
    "for labels in trainloader:\n",
    "    all_labels = torch.cat((all_labels, labels.cpu()), 0)\n",
    "\n",
    "print(all_labels.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T13:34:31.050562Z",
     "end_time": "2024-01-17T13:34:35.871672Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(all_labels[12])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T13:40:54.899526Z",
     "end_time": "2024-01-17T13:40:54.938906Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
